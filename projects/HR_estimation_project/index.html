<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Heart Rate Estimation from Video via CNN | Athar Mahmoudi </title> <meta name="author" content="Athar Mahmoudi"> <meta name="description" content="Estimating Heart Rate from Video Using CNNs and Transfer Learning"> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://athar70.github.io/projects/HR_estimation_project/"> <script src="/assets/js/theme.js?9a0c749ec5240d9cda97bc72359a72c0"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>initTheme();</script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <span class="font-weight-bold">Athar</span> Mahmoudi </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">About </a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">CV </a> </li> <li class="nav-item "> <a class="nav-link" href="/experience/">Experience </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">Publications </a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">Heart Rate Estimation from Video via CNN</h1> <p class="post-description">Estimating Heart Rate from Video Using CNNs and Transfer Learning</p> </header> <article> <h2 id="overview">Overview</h2> <p><strong>Heart Rate Estimation from Video via CNN</strong> explores a non-contact approach to estimating heart rate from facial video streams. Traditional heart rate measurements require physical sensors such as ECG or PPG, which can be intrusive and inconvenient. This project employs a <strong>Convolutional Neural Network (CNN)</strong> with transfer learning from the DenseNet-161 model, combined with multiple regression, to predict heart rate from facial images while participants watch video clips.</p> <p>By leveraging the publicly available <strong>AMIGOS dataset</strong>, which includes ECG signals, facial videos, and emotion annotations, this project demonstrates the feasibility of <strong>remote heart rate estimation</strong> through video-based physiological measurements.</p> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/HR_estimation.png" sizes="95vw"></source> <img src="/assets/img/HR_estimation.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="Process" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <h2 id="key-features">Key Features</h2> <ul> <li> <strong>CNN-based Heart Rate Estimation:</strong> A CNN model with transfer learning from <strong>DenseNet-161</strong> is used to predict heart rate from facial video frames.</li> <li> <p><strong>ECG Signal Processing:</strong> ECG signals are filtered using a Notch filter to remove noise, and heart rate is calculated using a sliding window approach.</p> </li> <li> <p><strong>Face Recognition and Normalization:</strong> Faces are detected, cropped, and normalized to 128x128 pixels from each video frame, which are then used for heart rate prediction.</p> </li> <li> <strong>AMIGOS Dataset:</strong> The project uses the publicly available <strong>AMIGOS dataset</strong>, which provides physiological signals and video data, allowing heart rate estimation to be correlated with participants’ emotions.</li> </ul> <h2 id="study-details">Study Details</h2> <ul> <li> <p><strong>Participants and Data Collection:</strong> The <strong>AMIGOS dataset</strong>, used for this project, consists of video recordings and physiological signals of participants watching emotional videos.</p> </li> <li> <p><strong>Training and Evaluation:</strong> Two evaluation approaches were used:</p> <ol> <li>Train on 35 participants and test on 5 unseen participants.</li> <li>Train on 75% of the videos from each participant and test on the remaining 25%.</li> </ol> <p>The results were measured using <strong>Root Mean Squared Error (RMSE)</strong>. The average RMSE for unseen participants was <strong>27.17 bpm</strong>, and for unseen videos, it was <strong>16.96 bpm</strong>, with a median of <strong>12.32 bpm</strong>.</p> </li> </ul> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/RMSE_1.png" sizes="95vw"></source> <img src="/assets/img/RMSE_1.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="RMSE for unseen participants" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/RMSE_2.png" sizes="95vw"></source> <img src="/assets/img/RMSE_2.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="RMSE for unseen videos" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <h2 id="methodology">Methodology</h2> <ul> <li> <p><strong>ECG Signal Denoising:</strong> The project applies a <strong>Notch filter</strong> to remove noise from ECG signals, followed by a windowing approach to estimate heart rate.</p> </li> <li> <p><strong>Face Recognition and Normalization:</strong> The face-recognition package detects and normalizes faces from video frames, ensuring each face image is consistent for heart rate prediction.</p> </li> <li> <p><strong>CNN and Transfer Learning:</strong> The <strong>DenseNet-161</strong> model is used for transfer learning, feeding facial images into a CNN. The CNN outputs are passed into a multiple regression model with three hidden layers to predict heart rate.</p> </li> <li> <p><strong>Loss Function and Optimizer:</strong> The model is trained using <strong>Mean Squared Error (MSE)</strong> as the loss function and the <strong>Adam optimizer</strong> for updating network weights.</p> </li> </ul> <h2 id="github-repository">GitHub Repository</h2> <p>Explore the full implementation, including the CNN model for heart rate estimation and ECG preprocessing pipeline, by visiting the <a href="https://github.com/athar70/Heart-Rate-Estimation" rel="external nofollow noopener" target="_blank">GitHub repository</a>. This repository includes code for training the model and evaluating results.</p> <h2 id="acknowledgments">Acknowledgments</h2> <p>The <strong>AMIGOS dataset</strong> used in this project is publicly available and was developed for research on affect, personality traits, and mood. The dataset includes physiological signals, such as ECG and facial video recordings, which were used in this project to develop and evaluate the heart rate estimation model. For more information about the dataset, visit <a href="http://www.eecs.qmul.ac.uk/mmv/datasets/amigos/index.html" rel="external nofollow noopener" target="_blank">AMIGOS dataset</a>.</p> <h2 id="future-work">Future Work</h2> <p>Possible future directions include:</p> <ul> <li> <strong>Reframing Heart Rate Estimation as Classification:</strong> Classifying heart rate into categories (e.g., normal, fast, slow) instead of predicting exact values may improve model accuracy.</li> <li> <strong>Exploring More Sophisticated Datasets:</strong> Investigating datasets with additional emotional and physiological annotations to study the correlation between emotions and heart rate.</li> <li> <strong>Improving Model Architectures:</strong> Future work could explore using <strong>RNNs</strong> or <strong>attention mechanisms</strong> to improve heart rate estimation accuracy.</li> </ul> </article> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2026 Athar Mahmoudi. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>addBackToTop();</script> </body> </html>